{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ニューラルネットワークの学習を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 損失関数の写像を定義\n",
    "def loss(t, f):\n",
    "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(t * tf.log(f))) # reduce_meanは不要か？(reduce_sum()の時点でスカラ値が返ってくる)\n",
    "    return cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 重みwを定義\n",
    "def weight(shape = []):\n",
    "    initial = tf.truncated_normal(shape, stddev = 0.01)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# バイアスbを定義\n",
    "def bias(dtype = tf.float32, shape = []):\n",
    "    initial = tf.zeros(shape, dtype = dtype)\n",
    "    return tf.Variable(initial) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# シグモイド関数の写像を定義\n",
    "def sigmoid(x):\n",
    "    return (1 /(1 + tf.exp(-x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q = 4 # 入力の数\n",
    "P = 4 # 中間層の数\n",
    "R = 3 # 出力の数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(dtype = tf.float32, shape = [None, Q])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = tf.placeholder(dtype = tf.float32, shape = [None, R])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W1 = weight(shape = [Q, P])\n",
    "b1 = bias(shape = [P])\n",
    "f1 = tf.matmul(X, W1) + b1\n",
    "sigm = sigmoid(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W2 = weight(shape = [P, R])\n",
    "b2 = bias(shape = [R])\n",
    "f2 = tf.matmul(sigm, W2) + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = tf.nn.softmax(f2) # 分類問題ではsoftmax()関数を使用する(出力の総計が1となる)\n",
    "loss = loss(t, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.001) # GradientDescentOptimizerのインスタンスを作成\n",
    "train_step = optimizer.minimize(loss) # 損失関数が最小となるようにtf.Variable()で作成した変数を調整する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "train_x = iris.data\n",
    "train_t = iris.target\n",
    "train_t = np.eye(3)[train_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 loss:164.79568481445312\n",
      "epoch : 100 loss:161.07754516601562\n",
      "epoch : 200 loss:96.02078247070312\n",
      "epoch : 300 loss:73.32796478271484\n",
      "epoch : 400 loss:59.992919921875\n",
      "epoch : 500 loss:47.323909759521484\n",
      "epoch : 600 loss:37.34531021118164\n",
      "epoch : 700 loss:30.397132873535156\n",
      "epoch : 800 loss:25.665224075317383\n",
      "epoch : 900 loss:22.36561393737793\n",
      "epoch : 1000 loss:19.982709884643555\n",
      "epoch : 1100 loss:18.201993942260742\n",
      "epoch : 1200 loss:16.830642700195312\n",
      "epoch : 1300 loss:15.747117042541504\n",
      "epoch : 1400 loss:14.872153282165527\n",
      "epoch : 1500 loss:14.152395248413086\n",
      "epoch : 1600 loss:13.550819396972656\n",
      "epoch : 1700 loss:13.041047096252441\n",
      "epoch : 1800 loss:12.603846549987793\n",
      "epoch : 1900 loss:12.224902153015137\n",
      "epoch : 2000 loss:11.89336109161377\n",
      "epoch : 2100 loss:11.600844383239746\n",
      "epoch : 2200 loss:11.3408203125\n",
      "epoch : 2300 loss:11.108115196228027\n",
      "epoch : 2400 loss:10.898554801940918\n",
      "epoch : 2500 loss:10.708793640136719\n",
      "epoch : 2600 loss:10.536091804504395\n",
      "epoch : 2700 loss:10.378157615661621\n",
      "epoch : 2800 loss:10.233121871948242\n",
      "epoch : 2900 loss:10.099397659301758\n",
      "epoch : 3000 loss:9.975654602050781\n",
      "epoch : 3100 loss:9.860761642456055\n",
      "epoch : 3200 loss:9.75374698638916\n",
      "epoch : 3300 loss:9.653773307800293\n",
      "epoch : 3400 loss:9.560139656066895\n",
      "epoch : 3500 loss:9.472207069396973\n",
      "epoch : 3600 loss:9.389444351196289\n",
      "epoch : 3700 loss:9.311362266540527\n",
      "epoch : 3800 loss:9.237550735473633\n",
      "epoch : 3900 loss:9.167640686035156\n",
      "epoch : 4000 loss:9.101300239562988\n",
      "epoch : 4100 loss:9.038235664367676\n",
      "epoch : 4200 loss:8.978192329406738\n",
      "epoch : 4300 loss:8.920931816101074\n",
      "epoch : 4400 loss:8.86624813079834\n",
      "epoch : 4500 loss:8.813950538635254\n",
      "epoch : 4600 loss:8.763875007629395\n",
      "epoch : 4700 loss:8.715852737426758\n",
      "epoch : 4800 loss:8.669764518737793\n",
      "epoch : 4900 loss:8.62546443939209\n",
      "epoch : 5000 loss:8.582840919494629\n",
      "epoch : 5100 loss:8.541790008544922\n",
      "epoch : 5200 loss:8.502222061157227\n",
      "epoch : 5300 loss:8.464030265808105\n",
      "epoch : 5400 loss:8.427152633666992\n",
      "epoch : 5500 loss:8.391493797302246\n",
      "epoch : 5600 loss:8.35699462890625\n",
      "epoch : 5700 loss:8.323583602905273\n",
      "epoch : 5800 loss:8.29120922088623\n",
      "epoch : 5900 loss:8.259819984436035\n",
      "epoch : 6000 loss:8.229347229003906\n",
      "epoch : 6100 loss:8.199750900268555\n",
      "epoch : 6200 loss:8.170992851257324\n",
      "epoch : 6300 loss:8.143023490905762\n",
      "epoch : 6400 loss:8.115806579589844\n",
      "epoch : 6500 loss:8.089303970336914\n",
      "epoch : 6600 loss:8.063488006591797\n",
      "epoch : 6700 loss:8.038320541381836\n",
      "epoch : 6800 loss:8.01377010345459\n",
      "epoch : 6900 loss:7.9898152351379395\n",
      "epoch : 7000 loss:7.966424942016602\n",
      "epoch : 7100 loss:7.943570613861084\n",
      "epoch : 7200 loss:7.921236515045166\n",
      "epoch : 7300 loss:7.899397373199463\n",
      "epoch : 7400 loss:7.8780293464660645\n",
      "epoch : 7500 loss:7.857118129730225\n",
      "epoch : 7600 loss:7.836640357971191\n",
      "epoch : 7700 loss:7.816586971282959\n",
      "epoch : 7800 loss:7.79692268371582\n",
      "epoch : 7900 loss:7.777650833129883\n",
      "epoch : 8000 loss:7.758749008178711\n",
      "epoch : 8100 loss:7.74020528793335\n",
      "epoch : 8200 loss:7.722000598907471\n",
      "epoch : 8300 loss:7.704127311706543\n",
      "epoch : 8400 loss:7.68657112121582\n",
      "epoch : 8500 loss:7.669318199157715\n",
      "epoch : 8600 loss:7.652366638183594\n",
      "epoch : 8700 loss:7.6356892585754395\n",
      "epoch : 8800 loss:7.619299411773682\n",
      "epoch : 8900 loss:7.60316276550293\n",
      "epoch : 9000 loss:7.587286949157715\n",
      "epoch : 9100 loss:7.571658611297607\n",
      "epoch : 9200 loss:7.556266784667969\n",
      "epoch : 9300 loss:7.541104793548584\n",
      "epoch : 9400 loss:7.526167869567871\n",
      "epoch : 9500 loss:7.511447906494141\n",
      "epoch : 9600 loss:7.496936798095703\n",
      "epoch : 9700 loss:7.482630729675293\n",
      "epoch : 9800 loss:7.4685139656066895\n",
      "epoch : 9900 loss:7.454591274261475\n",
      "epoch : 10000 loss:7.440852165222168\n",
      "epoch : 10100 loss:7.4272918701171875\n",
      "epoch : 10200 loss:7.413901329040527\n",
      "epoch : 10300 loss:7.400687217712402\n",
      "epoch : 10400 loss:7.387629985809326\n",
      "epoch : 10500 loss:7.37473726272583\n",
      "epoch : 10600 loss:7.361993312835693\n",
      "epoch : 10700 loss:7.349400997161865\n",
      "epoch : 10800 loss:7.336953163146973\n",
      "epoch : 10900 loss:7.324653625488281\n",
      "epoch : 11000 loss:7.31248664855957\n",
      "epoch : 11100 loss:7.3004536628723145\n",
      "epoch : 11200 loss:7.2885541915893555\n",
      "epoch : 11300 loss:7.276780128479004\n",
      "epoch : 11400 loss:7.265127658843994\n",
      "epoch : 11500 loss:7.253602981567383\n",
      "epoch : 11600 loss:7.242195129394531\n",
      "epoch : 11700 loss:7.230899333953857\n",
      "epoch : 11800 loss:7.219721794128418\n",
      "epoch : 11900 loss:7.20864725112915\n",
      "epoch : 12000 loss:7.197683811187744\n",
      "epoch : 12100 loss:7.186824798583984\n",
      "epoch : 12200 loss:7.176069259643555\n",
      "epoch : 12300 loss:7.165414333343506\n",
      "epoch : 12400 loss:7.154858589172363\n",
      "epoch : 12500 loss:7.144396781921387\n",
      "epoch : 12600 loss:7.134033679962158\n",
      "epoch : 12700 loss:7.123754978179932\n",
      "epoch : 12800 loss:7.113574028015137\n",
      "epoch : 12900 loss:7.103479385375977\n",
      "epoch : 13000 loss:7.093470573425293\n",
      "epoch : 13100 loss:7.083554744720459\n",
      "epoch : 13200 loss:7.073716640472412\n",
      "epoch : 13300 loss:7.063959121704102\n",
      "epoch : 13400 loss:7.054286003112793\n",
      "epoch : 13500 loss:7.044696807861328\n",
      "epoch : 13600 loss:7.035177707672119\n",
      "epoch : 13700 loss:7.025735855102539\n",
      "epoch : 13800 loss:7.0163798332214355\n",
      "epoch : 13900 loss:7.0070929527282715\n",
      "epoch : 14000 loss:6.997879505157471\n",
      "epoch : 14100 loss:6.988736629486084\n",
      "epoch : 14200 loss:6.979671001434326\n",
      "epoch : 14300 loss:6.970677375793457\n",
      "epoch : 14400 loss:6.961746692657471\n",
      "epoch : 14500 loss:6.952890872955322\n",
      "epoch : 14600 loss:6.9440999031066895\n",
      "epoch : 14700 loss:6.935378551483154\n",
      "epoch : 14800 loss:6.926724433898926\n",
      "epoch : 14900 loss:6.918130397796631\n",
      "epoch : 15000 loss:6.909609317779541\n",
      "epoch : 15100 loss:6.90115213394165\n",
      "epoch : 15200 loss:6.892755031585693\n",
      "epoch : 15300 loss:6.884425640106201\n",
      "epoch : 15400 loss:6.876152992248535\n",
      "epoch : 15500 loss:6.867949485778809\n",
      "epoch : 15600 loss:6.859807014465332\n",
      "epoch : 15700 loss:6.851722240447998\n",
      "epoch : 15800 loss:6.843701362609863\n",
      "epoch : 15900 loss:6.835735321044922\n",
      "epoch : 16000 loss:6.827837944030762\n",
      "epoch : 16100 loss:6.819991111755371\n",
      "epoch : 16200 loss:6.812211513519287\n",
      "epoch : 16300 loss:6.804487705230713\n",
      "epoch : 16400 loss:6.796821117401123\n",
      "epoch : 16500 loss:6.789209842681885\n",
      "epoch : 16600 loss:6.7816691398620605\n",
      "epoch : 16700 loss:6.774176597595215\n",
      "epoch : 16800 loss:6.766739368438721\n",
      "epoch : 16900 loss:6.759365558624268\n",
      "epoch : 17000 loss:6.7520432472229\n",
      "epoch : 17100 loss:6.744776248931885\n",
      "epoch : 17200 loss:6.737575054168701\n",
      "epoch : 17300 loss:6.730420112609863\n",
      "epoch : 17400 loss:6.723328590393066\n",
      "epoch : 17500 loss:6.716285705566406\n",
      "epoch : 17600 loss:6.709303379058838\n",
      "epoch : 17700 loss:6.702372074127197\n",
      "epoch : 17800 loss:6.695497989654541\n",
      "epoch : 17900 loss:6.6886820793151855\n",
      "epoch : 18000 loss:6.681916236877441\n",
      "epoch : 18100 loss:6.675206184387207\n",
      "epoch : 18200 loss:6.668547630310059\n",
      "epoch : 18300 loss:6.661943435668945\n",
      "epoch : 18400 loss:6.655402183532715\n",
      "epoch : 18500 loss:6.6489081382751465\n",
      "epoch : 18600 loss:6.642464637756348\n",
      "epoch : 18700 loss:6.636075973510742\n",
      "epoch : 18800 loss:6.629741668701172\n",
      "epoch : 18900 loss:6.623462200164795\n",
      "epoch : 19000 loss:6.617231845855713\n",
      "epoch : 19100 loss:6.611059665679932\n",
      "epoch : 19200 loss:6.604935169219971\n",
      "epoch : 19300 loss:6.598865509033203\n",
      "epoch : 19400 loss:6.5928497314453125\n",
      "epoch : 19500 loss:6.586879253387451\n",
      "epoch : 19600 loss:6.580963134765625\n",
      "epoch : 19700 loss:6.57509708404541\n",
      "epoch : 19800 loss:6.5692830085754395\n",
      "epoch : 19900 loss:6.56352424621582\n",
      "epoch : 20000 loss:6.5578155517578125\n",
      "epoch : 20100 loss:6.552151203155518\n",
      "epoch : 20200 loss:6.546543121337891\n",
      "epoch : 20300 loss:6.540979385375977\n",
      "epoch : 20400 loss:6.535471439361572\n",
      "epoch : 20500 loss:6.530010223388672\n",
      "epoch : 20600 loss:6.524595737457275\n",
      "epoch : 20700 loss:6.519232273101807\n",
      "epoch : 20800 loss:6.513920307159424\n",
      "epoch : 20900 loss:6.508657932281494\n",
      "epoch : 21000 loss:6.503439426422119\n",
      "epoch : 21100 loss:6.498269081115723\n",
      "epoch : 21200 loss:6.493143081665039\n",
      "epoch : 21300 loss:6.488069534301758\n",
      "epoch : 21400 loss:6.483040809631348\n",
      "epoch : 21500 loss:6.478063583374023\n",
      "epoch : 21600 loss:6.473130226135254\n",
      "epoch : 21700 loss:6.468240737915039\n",
      "epoch : 21800 loss:6.46339750289917\n",
      "epoch : 21900 loss:6.4585981369018555\n",
      "epoch : 22000 loss:6.453849792480469\n",
      "epoch : 22100 loss:6.449143886566162\n",
      "epoch : 22200 loss:6.444480895996094\n",
      "epoch : 22300 loss:6.43986177444458\n",
      "epoch : 22400 loss:6.435284614562988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 22500 loss:6.430755615234375\n",
      "epoch : 22600 loss:6.426266193389893\n",
      "epoch : 22700 loss:6.421820640563965\n",
      "epoch : 22800 loss:6.417418479919434\n",
      "epoch : 22900 loss:6.413053512573242\n",
      "epoch : 23000 loss:6.408731937408447\n",
      "epoch : 23100 loss:6.404449939727783\n",
      "epoch : 23200 loss:6.400212287902832\n",
      "epoch : 23300 loss:6.396017551422119\n",
      "epoch : 23400 loss:6.39185905456543\n",
      "epoch : 23500 loss:6.387733459472656\n",
      "epoch : 23600 loss:6.383656024932861\n",
      "epoch : 23700 loss:6.379615783691406\n",
      "epoch : 23800 loss:6.375609397888184\n",
      "epoch : 23900 loss:6.371649265289307\n",
      "epoch : 24000 loss:6.367721080780029\n",
      "epoch : 24100 loss:6.363826751708984\n",
      "epoch : 24200 loss:6.359971046447754\n",
      "epoch : 24300 loss:6.356152534484863\n",
      "epoch : 24400 loss:6.3523783683776855\n",
      "epoch : 24500 loss:6.348632335662842\n",
      "epoch : 24600 loss:6.344917297363281\n",
      "epoch : 24700 loss:6.341244220733643\n",
      "epoch : 24800 loss:6.337597370147705\n",
      "epoch : 24900 loss:6.333988666534424\n",
      "epoch : 25000 loss:6.330414772033691\n",
      "epoch : 25100 loss:6.326871395111084\n",
      "epoch : 25200 loss:6.323361873626709\n",
      "epoch : 25300 loss:6.319886207580566\n",
      "epoch : 25400 loss:6.316440105438232\n",
      "epoch : 25500 loss:6.313019752502441\n",
      "epoch : 25600 loss:6.309637546539307\n",
      "epoch : 25700 loss:6.306284427642822\n",
      "epoch : 25800 loss:6.302964687347412\n",
      "epoch : 25900 loss:6.299671173095703\n",
      "epoch : 26000 loss:6.2964067459106445\n",
      "epoch : 26100 loss:6.293166637420654\n",
      "epoch : 26200 loss:6.2899580001831055\n",
      "epoch : 26300 loss:6.28678560256958\n",
      "epoch : 26400 loss:6.283633232116699\n",
      "epoch : 26500 loss:6.28051233291626\n",
      "epoch : 26600 loss:6.277413845062256\n",
      "epoch : 26700 loss:6.2743401527404785\n",
      "epoch : 26800 loss:6.271295070648193\n",
      "epoch : 26900 loss:6.268278121948242\n",
      "epoch : 27000 loss:6.26528787612915\n",
      "epoch : 27100 loss:6.262317180633545\n",
      "epoch : 27200 loss:6.259371757507324\n",
      "epoch : 27300 loss:6.25645112991333\n",
      "epoch : 27400 loss:6.2535552978515625\n",
      "epoch : 27500 loss:6.2506842613220215\n",
      "epoch : 27600 loss:6.247833728790283\n",
      "epoch : 27700 loss:6.2450103759765625\n",
      "epoch : 27800 loss:6.242206573486328\n",
      "epoch : 27900 loss:6.2394256591796875\n",
      "epoch : 28000 loss:6.236662864685059\n",
      "epoch : 28100 loss:6.233919143676758\n",
      "epoch : 28200 loss:6.231203556060791\n",
      "epoch : 28300 loss:6.228505611419678\n",
      "epoch : 28400 loss:6.225830078125\n",
      "epoch : 28500 loss:6.223174571990967\n",
      "epoch : 28600 loss:6.220533847808838\n",
      "epoch : 28700 loss:6.217916011810303\n",
      "epoch : 28800 loss:6.2153120040893555\n",
      "epoch : 28900 loss:6.212734222412109\n",
      "epoch : 29000 loss:6.210170745849609\n",
      "epoch : 29100 loss:6.207624435424805\n",
      "epoch : 29200 loss:6.205098628997803\n",
      "epoch : 29300 loss:6.202584266662598\n",
      "epoch : 29400 loss:6.200087547302246\n",
      "epoch : 29500 loss:6.197615623474121\n",
      "epoch : 29600 loss:6.195155143737793\n",
      "epoch : 29700 loss:6.192711353302002\n",
      "epoch : 29800 loss:6.1902852058410645\n",
      "epoch : 29900 loss:6.187867164611816\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 30000\n",
    "for epoch in range(num_epoch):\n",
    "    sess.run(train_step, feed_dict = {X: train_x, t: train_t})\n",
    "    if epoch % 100 == 0:\n",
    "        train_loss = sess.run(loss, feed_dict = {X: train_x, t: train_t}) # 損失関数の出力値を表示\n",
    "        print('epoch : {} loss:{}'.format(epoch, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
